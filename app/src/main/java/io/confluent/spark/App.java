/*
 * This Java source file was generated by the Gradle 'init' task.
 */
package io.confluent.spark;

import org.apache.commons.cli.CommandLine;

import java.io.FileReader;
import java.io.IOException;
import java.util.Properties;

import org.apache.commons.cli.CommandLineParser;
import org.apache.commons.cli.DefaultParser;
import org.apache.commons.cli.Option;
import org.apache.commons.cli.Options;
import org.apache.commons.cli.ParseException;
import org.apache.kafka.common.serialization.Serdes;
import org.apache.kafka.streams.KafkaStreams;
import org.apache.kafka.streams.KeyValue;
import org.apache.kafka.streams.StreamsBuilder;
import org.apache.kafka.streams.Topology;
import org.apache.kafka.streams.kstream.Produced;
import org.json.simple.parser.JSONParser;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.json.simple.JSONArray;
import org.json.simple.JSONObject;
import org.apache.kafka.streams.kstream.Consumed;
import org.apache.kafka.streams.kstream.KeyValueMapper;


public class App {
    Logger logger = LoggerFactory.getLogger(App.class);
    public String getGreeting() {
        return "Hello World!";
    }

    private String fromTopic;
    private String toTopic;
    private String clusterName;
    private String connectorName;
    private String keyFormat;
    // private String valueFormat;

    public static void main(String[] args) {
        Options options = new Options();
    
        options.addOption(new Option("f", "file", true, "properties file."));
        options.addOption(new Option("t", "test", false, "is test"));
                CommandLineParser parser = new DefaultParser();
        App app = new App();

        try {
            Properties props = new Properties();
            CommandLine cmd = parser.parse(options, args);
            String filename = cmd.getOptionValue("f");
            boolean isTest = cmd.hasOption("t");

            app.logger.info("###### Properties file name : " + filename);
            
            if( filename != null ) {
                props.load(new FileReader(filename));
            } else if ( isTest ) {
                props.load(app.getClass().getClassLoader().getResource("server.properties").openStream());
            } else {
                app.logger.error("properties fils open error");
            }

            StreamExecutionContext.setSerdesConfig(props);

            app.getProps(props);

            Topology topology = app.buildTopology();
            KafkaStreams streams = new KafkaStreams(topology, props);
            Runtime.getRuntime().addShutdownHook(new Thread(streams::close));

            streams.start();
    
        } catch(ParseException e) {
            e.printStackTrace();
        } catch(IOException e) {
            e.printStackTrace();
        } catch(Exception e) {
            e.printStackTrace();
        }
    }
    
    private void getProps(Properties props) throws Exception {
        this.fromTopic = errorIfEmpty(props.getProperty("srm.mig.source.topic.name"));
        this.toTopic = errorIfEmpty(props.getProperty("srm.mig.target.topic.name"));
        this.connectorName = props.getProperty("srm.mig.target.connector.name");
        this.keyFormat = errorIfEmpty(props.getProperty("srm.mig.target.key.format"));        
        this.clusterName = props.getProperty("srm.mig.target.cluster.name");

        if( isNullOrEmpty(this.clusterName)) {
            if(this.keyFormat.indexOf("CLUSTERNAME") < 0 ) {
                this.clusterName = null;
            } else {
                throw new Exception("key format has '$CLUSTERNAME' buth 'srm.mig.target.cluster.name' in properties file is empty");
            }
        }
        // this.valueFormat = errorIfEmpty(props.getProperty("srm.mig.target.value.format"));

        logger.info("fromTopic : " + fromTopic);
        logger.info("toTopic : " + toTopic);
        logger.info("connectorName : " + connectorName);
        logger.info("keyFormat : " + keyFormat);
        logger.info("clusterName : " + clusterName);
        
    }

    private String errorIfEmpty(String s) throws Exception {
        if ( isNullOrEmpty(s) ) {
            throw new Exception("'" + s +"' in properties file is empty");
        } 
        return s;
    }

    private boolean isNullOrEmpty(String s) {
        return s== null || s.trim().length() == 0;
    }

    JSONParser parser = new JSONParser();

    private String createKey(String key)  {
        try {
            Object obj = parser.parse(key); 
            JSONArray jsonArr = (JSONArray)obj;
    
            // jsonArr에서 하나씩 JSONObject로 cast해서 사용
            if (jsonArr.size() == 2){
                JSONObject jsonObj = (JSONObject)jsonArr.get(1);
                String topicName = (String)jsonObj.get("topic");
                String partition = jsonObj.get("partition").toString();
                String sb = new StringBuilder(keyFormat).toString();
                sb = sb.replaceAll("\\$CONNECTORNAME", connectorName).replaceAll("\\$TOPICNAME", topicName).replaceAll("\\$PARTITION", partition);
                if( clusterName != null) {
                    sb = sb.replaceAll("\\$CLUSTERNAME", clusterName);
                }

                return sb;
            } 
            logger.info("return 1");
            return "";
        } catch( Exception e)  {
            logger.error("fail to convert key", e);
            return "";
        }

    }

    private Topology buildTopology() {
        StreamsBuilder builder = new StreamsBuilder();
        builder.stream(fromTopic, Consumed.with(Serdes.String(), Serdes.String()))
        .map(new KeyValueMapper<String, String, KeyValue<String, String>>() {
            @Override
            public KeyValue<String, String> apply(String k, String v) {
                    String key = createKey(k);
                    if( key == null || key.length() <= 0 ) {
                        logger.error("skip message : invalid key  '" + k + "'");
                    }
                    return new KeyValue<>(key, v);
                }
            })
        .filter((key, value) -> key != null && key.length() > 0)
        .to(toTopic, Produced.with(Serdes.String(), Serdes.String()));
    
        return builder.build();
    }
}
