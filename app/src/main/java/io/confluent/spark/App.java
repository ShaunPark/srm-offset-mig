/*
 * This Java source file was generated by the Gradle 'init' task.
 */
package io.confluent.spark;

import org.apache.commons.cli.CommandLine;

import java.io.FileReader;
import java.io.IOException;
import java.util.Map;
import java.util.Properties;

import org.apache.commons.cli.CommandLineParser;
import org.apache.commons.cli.DefaultParser;
import org.apache.commons.cli.Option;
import org.apache.commons.cli.Options;
import org.apache.commons.cli.ParseException;
import org.apache.kafka.common.TopicPartition;
import org.apache.kafka.common.serialization.Serdes;
import org.apache.kafka.streams.KafkaStreams;
import org.apache.kafka.streams.KeyValue;
import org.apache.kafka.streams.StreamsBuilder;
import org.apache.kafka.streams.Topology;
import org.apache.kafka.streams.kstream.Produced;
import org.json.simple.parser.JSONParser;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.apache.kafka.streams.kstream.Consumed;
import org.apache.kafka.streams.kstream.KeyValueMapper;
import org.apache.kafka.streams.kstream.Printed;


public class App {
    Logger logger = LoggerFactory.getLogger(App.class);
    public String getGreeting() {
        return "Hello World!";
    }

    private String fromTopic;
    private String toTopic;
    private TargetOffsetLoader tgt;

    public static void main(String[] args) {
        Options options = new Options();
    
        options.addOption(new Option("f", "file", true, "properties file."));
        options.addOption(new Option("t", "test", false, "is test"));
                CommandLineParser parser = new DefaultParser();
        App app = new App();

        try {
            Properties props = new Properties();
            CommandLine cmd = parser.parse(options, args);
            String filename = cmd.getOptionValue("f");
            boolean isTest = cmd.hasOption("t");

            app.logger.info("###### Properties file name : " + filename);
            
            if( filename != null ) {
                props.load(new FileReader(filename));
            }else {
            // } else if ( isTest ) {
                props.load(app.getClass().getClassLoader().getResource("server.properties").openStream());
            // } else {
            //     app.logger.error("properties fils open error");
            }

            StreamExecutionContext.setSerdesConfig(props);

            app.getProps(props);
            app.processOffsetKey(props);
    
            app.logger.info("###### End of Load Target Key " + filename);

            Topology topology = app.buildTopology();
            KafkaStreams streams = new KafkaStreams(topology, props);
            Runtime.getRuntime().addShutdownHook(new Thread(streams::close));

            streams.start();
   
        } catch(ParseException e) {
            e.printStackTrace();
        } catch(IOException e) {
            e.printStackTrace();
        } catch(Exception e) {
            e.printStackTrace();
        }
    }

    private void processOffsetKey(Properties props) throws Exception {
        tgt = new TargetOffsetLoader(this.toTopic, props);
        Map<TopicPartition, Long> offsetMap = tgt.getLasteOffsets(props);
        
        offsetMap.forEach((k, v)-> { logger.info("######## offset " + v.longValue());});
        tgt.loaddOffsets(props, offsetMap);
    }
    
    private void getProps(Properties props) throws Exception {
        this.fromTopic = errorIfEmpty(props.getProperty("srm.mig.source.topic.name"));
        this.toTopic = errorIfEmpty(props.getProperty("srm.mig.target.topic.name"));

        logger.info("fromTopic : " + fromTopic);
        logger.info("toTopic : " + toTopic);
    }

    private String errorIfEmpty(String s) throws Exception {
        if ( isNullOrEmpty(s) ) {
            throw new Exception("'" + s +"' in properties file is empty");
        } 
        return s;
    }

    private boolean isNullOrEmpty(String s) {
        return s== null || s.trim().length() == 0;
    }

    JSONParser parser = new JSONParser();

    private String getKey(String key)  {
        return tgt.getKey(key);
    }

    private Topology buildTopology() {
        StreamsBuilder builder = new StreamsBuilder();
        builder.stream(fromTopic, Consumed.with(Serdes.String(), Serdes.String()))
        .map(new KeyValueMapper<String, String, KeyValue<String, String>>() {
            @Override
            public KeyValue<String, String> apply(String k, String v) {
                    String key = getKey(k);
                    if( key == null || key.length() <= 0 ) {
                        logger.error("skip message : invalid key  '" + k + "'");
                    }
                    return new KeyValue<>(key, v);
                }
            })
        .filter((key, value) -> key != null && key.length() > 0)
        //.print(Printed.toSysOut());
        .to(toTopic, Produced.with(Serdes.String(), Serdes.String()));
    
        return builder.build();
    }
}
